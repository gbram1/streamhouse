# Phase 4: Multi-Agent Architecture - Overview

**Status**: âœ… Complete (Phases 4.1 & 4.2)
**Next**: Phase 4.3 (Partition Assignment)

## Table of Contents

1. [Introduction](#introduction)
2. [Architecture](#architecture)
3. [Components](#components)
4. [Coordination Mechanisms](#coordination-mechanisms)
5. [Failure Scenarios](#failure-scenarios)
6. [Performance Characteristics](#performance-characteristics)
7. [Implementation Status](#implementation-status)

---

## Introduction

Phase 4 transforms StreamHouse from a **single-agent system** into a **distributed multi-agent system** that can horizontally scale across multiple machines.

### What Problem Does This Solve?

**Before Phase 4** (Single Agent):
- âœ… Simple deployment (one process)
- âœ… No coordination needed
- âŒ Limited throughput (single machine)
- âŒ Single point of failure
- âŒ Cannot scale beyond one machine's resources

**After Phase 4** (Multi-Agent):
- âœ… Horizontal scalability (add more agents = more throughput)
- âœ… High availability (agents fail independently)
- âœ… Load distribution (partitions spread across agents)
- âš ï¸ Requires coordination (PostgreSQL-based leases)

### Real-World Example

```
Before (1 agent):
- Throughput: 10,000 writes/sec
- Availability: 99.5% (single point of failure)

After (6 agents):
- Throughput: 60,000 writes/sec (6x improvement)
- Availability: 99.99% (agents fail independently)
- Cost: Same (S3 is the bottleneck, not compute)
```

---

## Architecture

### High-Level Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PostgreSQL                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   agents     â”‚  â”‚partition_    â”‚  â”‚   metadata      â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  leases      â”‚  â”‚   (topics,      â”‚  â”‚
â”‚  â”‚ - heartbeat  â”‚  â”‚ - leader     â”‚  â”‚   segments,     â”‚  â”‚
â”‚  â”‚ - started_at â”‚  â”‚ - epoch      â”‚  â”‚   offsets)      â”‚  â”‚
â”‚  â”‚ - metadata   â”‚  â”‚ - expires_at â”‚  â”‚                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚ Coordination Plane
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ Agent 1 â”‚         â”‚ Agent 2 â”‚         â”‚ Agent 3 â”‚
   â”‚         â”‚         â”‚         â”‚         â”‚         â”‚
   â”‚ orders/0â”‚         â”‚ orders/1â”‚         â”‚ orders/2â”‚
   â”‚ users/0 â”‚         â”‚ users/1 â”‚         â”‚ users/2 â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      S3       â”‚
                    â”‚  (Segments)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      Data Plane
```

### Key Concepts

1. **Agent**: Stateless worker process that manages partitions
2. **Partition Lease**: Time-based lock that grants write permission
3. **Epoch**: Monotonically increasing counter for split-brain prevention
4. **Heartbeat**: Periodic "I'm alive" signal to metadata store
5. **Failover**: Automatic lease takeover when agent dies

---

## Components

### 1. Agent (Core Coordinator)

**Location**: `crates/streamhouse-agent/src/agent.rs`

**Purpose**: Main lifecycle manager for a StreamHouse instance.

**Responsibilities**:
- Register/deregister with metadata store
- Start/stop background tasks (heartbeat, lease renewal)
- Provide access to LeaseManager
- Handle graceful shutdown

**Example**:
```rust
let agent = Agent::builder()
    .agent_id("agent-us-east-1a-001")
    .address("10.0.1.5:9090")
    .availability_zone("us-east-1a")
    .agent_group("prod")
    .metadata_store(metadata_store)
    .build()
    .await?;

agent.start().await?; // Register + start tasks
// ... serve traffic ...
agent.stop().await?;  // Clean shutdown
```

**Lifecycle**:
```
Created â†’ Started â†’ Stopped
           â†“
    [Heartbeat Task] â† 20s interval
    [Lease Renewal] â† 10s interval
```

### 2. HeartbeatTask (Liveness Detection)

**Location**: `crates/streamhouse-agent/src/heartbeat.rs`

**Purpose**: Periodic "I'm alive" signal to PostgreSQL.

**How It Works**:
1. Every 20 seconds, update `agents.last_heartbeat` in PostgreSQL
2. If update fails, log error but continue (transient failures OK)
3. Run until agent stops or receives shutdown signal

**Failure Detection**:
- Agents with `last_heartbeat > 60s old` are considered **dead**
- `list_agents()` automatically filters out stale agents
- Monitoring dashboards show heartbeat age

**Configuration**:
```rust
Agent::builder()
    .heartbeat_interval(Duration::from_secs(20)) // Default: 20s
    .heartbeat_timeout(Duration::from_secs(60))  // Default: 60s
```

### 3. LeaseManager (Partition Leadership)

**Location**: `crates/streamhouse-agent/src/lease_manager.rs`

**Purpose**: Acquire and maintain partition leadership using time-based leases.

**How It Works**:

#### Lease Acquisition
```rust
// 1. Acquire lease before writing
let epoch = agent.lease_manager()
    .ensure_lease("orders", 0)
    .await?;

// 2. Prepare write (upload to S3)
let segment = writer.finalize().await?;

// 3. Validate epoch before committing metadata
validate_epoch(agent.lease_manager(), "orders", 0, epoch).await?;

// 4. Safe to commit metadata
metadata.add_segment(segment).await?;
```

#### Lease Renewal (Automatic)
```
T=0s   : Acquire lease (epoch=1, expires_at=30s)
T=10s  : Renew lease (expires_at=40s)
T=20s  : Renew lease (expires_at=50s)
T=30s  : Renew lease (expires_at=60s)
...
```

#### Epoch Fencing
```
Agent 1: epoch=1 (has lease)
Agent 2: tries to acquire â†’ FAILS (Agent 1 holds lease)

Agent 1 crashes (no renewal)
T=30s: Lease expires

Agent 2: acquires lease (epoch=2)
Agent 1: wakes up, tries to write with epoch=1 â†’ REJECTED (stale epoch)
```

**Key Methods**:
- `ensure_lease(topic, partition_id)` â†’ Returns epoch
- `validate_epoch(manager, topic, partition_id, epoch)` â†’ Prevents stale writes
- `release_lease(topic, partition_id)` â†’ Graceful cleanup
- `release_all_leases()` â†’ Shutdown cleanup

---

## Coordination Mechanisms

### 1. Lease-Based Leadership

**Problem**: Multiple agents trying to write to the same partition causes data corruption.

**Solution**: Time-based leases with compare-and-swap (CAS).

**PostgreSQL Schema**:
```sql
CREATE TABLE partition_leases (
    topic VARCHAR(255),
    partition_id INT,
    leader_agent_id VARCHAR(255),
    lease_expires_at BIGINT,  -- Absolute timestamp
    acquired_at BIGINT,
    epoch BIGINT UNSIGNED,
    PRIMARY KEY (topic, partition_id)
);
```

**Acquisition Logic** (CAS):
```sql
-- Only succeeds if:
-- 1. No lease exists, OR
-- 2. Lease expired, OR
-- 3. Same agent renewing
UPDATE partition_leases
SET
    leader_agent_id = 'agent-1',
    lease_expires_at = NOW() + 30000,  -- 30 seconds
    epoch = epoch + 1
WHERE topic = 'orders'
  AND partition_id = 0
  AND (
      lease_expires_at < NOW()  -- Expired
      OR leader_agent_id = 'agent-1'  -- Same agent
  );
```

### 2. Epoch Fencing

**Problem**: Split-brain scenario where two agents think they own the same partition.

**Solution**: Monotonically increasing epoch number.

**How It Works**:
1. Every lease acquisition increments the epoch
2. Before writing metadata, validate epoch hasn't changed
3. If epoch changed, abort write (another agent took over)

**Example**:
```rust
// Agent 1
let epoch = lease_manager.ensure_lease("orders", 0).await?; // epoch=1

// ... 5 seconds pass, Agent 1 crashes ...

// Agent 2 (new leader)
let epoch2 = lease_manager.ensure_lease("orders", 0).await?; // epoch=2

// Agent 1 wakes up, tries to commit
validate_epoch(&lease_manager, "orders", 0, epoch).await?;
// âŒ ERROR: StaleEpoch { expected: 1, actual: 2 }
```

### 3. Heartbeat Mechanism

**Problem**: How do agents know when another agent has died?

**Solution**: Periodic heartbeat updates to PostgreSQL.

**Detection Timeline**:
```
T=0s   : Agent starts, heartbeat=0
T=20s  : Heartbeat update (heartbeat=20000)
T=40s  : Heartbeat update (heartbeat=40000)
T=60s  : Agent crashes (no more updates)
T=80s  : Other agents see last_heartbeat=40000 (40s old)
T=120s : Agent considered DEAD (60s timeout exceeded)
```

**Querying Live Agents**:
```sql
SELECT * FROM agents
WHERE last_heartbeat > (NOW() - 60000); -- 60s window
```

---

## Failure Scenarios

### Scenario 1: Agent Crashes

**Timeline**:
```
T=0s   : Agent-1 holds lease on orders/0 (epoch=1)
T=10s  : Agent-1 crashes (process killed)
T=30s  : Lease expires (no renewal)
T=31s  : Agent-2 acquires lease (epoch=2)
T=35s  : Agent-2 starts writing to orders/0
```

**Impact**:
- **Data Loss**: None (S3 writes are durable)
- **Downtime**: 30 seconds (lease duration)
- **Recovery**: Automatic (no manual intervention)

### Scenario 2: Network Partition

**Timeline**:
```
T=0s   : Agent-1 has lease (epoch=1)
T=10s  : Network partition (Agent-1 can't reach PostgreSQL)
T=30s  : Lease expires
T=31s  : Agent-2 acquires lease (epoch=2)
T=35s  : Agent-1 network recovers
T=40s  : Agent-1 tries to write â†’ REJECTED (stale epoch)
```

**Protection**: Epoch fencing prevents split-brain.

### Scenario 3: PostgreSQL Failure

**Impact**: **All agents stop writing** (coordination plane down).

**Recovery**:
1. PostgreSQL recovers (primary or replica promoted)
2. Agents reconnect and renew leases
3. Writes resume

**Mitigation**: Use PostgreSQL with replication (high availability).

### Scenario 4: S3 Outage

**Impact**: **All agents can't write segments** (data plane down).

**Behavior**:
- Agents keep leases (coordination still works)
- Writes buffer in memory or fail
- When S3 recovers, writes resume

---

## Performance Characteristics

### Lease Operations

| Operation | Latency | Frequency |
|-----------|---------|-----------|
| **Acquire Lease** (first time) | 5-10ms | Once per partition |
| **Ensure Lease** (cached) | < 1Âµs | Every write |
| **Renew Lease** | 5-10ms | Every 10s per partition |
| **Release Lease** | 5-10ms | On shutdown |

### Heartbeat Operations

| Operation | Latency | Frequency |
|-----------|---------|-----------|
| **Heartbeat Update** | 5-10ms | Every 20s per agent |

### Overhead per Agent

**Example**: Agent holding 100 partitions
- Lease renewals: 100 UPDATEs / 10s = **10 qps**
- Heartbeat: 1 UPDATE / 20s = **0.05 qps**
- **Total**: ~10 qps per agent

**PostgreSQL Load**:
- 10 agents Ã— 10 qps = **100 qps** (easily handled by PostgreSQL)

### Failover Performance

| Metric | Value |
|--------|-------|
| **Maximum Failover Time** | 30s (lease duration) |
| **Typical Failover Time** | 10-20s (depends on renewal cycle) |
| **Detection Time** | 60s (heartbeat timeout) |

---

## Implementation Status

### âœ… Phase 4.1: Multi-Agent Infrastructure (Complete)

**Implemented**:
- Agent lifecycle management (start/stop)
- Agent registration/deregistration
- Heartbeat background task
- Agent discovery (by zone, by group)
- Graceful shutdown

**Files**:
- `crates/streamhouse-agent/src/agent.rs` (420 lines)
- `crates/streamhouse-agent/src/heartbeat.rs` (253 lines)
- `crates/streamhouse-agent/src/error.rs` (36 lines)
- `crates/streamhouse-agent/examples/simple_agent.rs` (71 lines)
- `crates/streamhouse-agent/tests/multi_agent_test.rs` (489 lines)

**Tests**: 14 tests passing

### âœ… Phase 4.2: Partition Leadership (Complete)

**Implemented**:
- Lease acquisition with CAS
- Automatic lease renewal (every 10s)
- Epoch fencing for split-brain prevention
- Lease cache for fast lookups
- Graceful lease release on shutdown

**Files**:
- `crates/streamhouse-agent/src/lease_manager.rs` (471 lines)
- `crates/streamhouse-agent/tests/lease_coordination_test.rs` (530 lines)

**Tests**: 8 new tests (22 total passing)

### ðŸ”„ Phase 4.3: Partition Assignment (Next)

**Goal**: Automatically distribute partitions across agents.

**Features**:
- Watch for agent joins/leaves
- Assign partitions using consistent hashing
- Rebalance on topology changes
- Handle agent failures (automatic reassignment)

**Planned Components**:
- `PartitionAssigner` - Assignment algorithm
- `RebalanceTask` - Background rebalancing
- Assignment persistence in metadata store

---

## Configuration Reference

### Agent Configuration

```rust
Agent::builder()
    .agent_id("agent-1")                              // Required: Unique agent ID
    .address("10.0.1.5:9090")                          // Required: Agent address
    .availability_zone("us-east-1a")                   // Optional: Default "default"
    .agent_group("prod")                               // Optional: Default "default"
    .heartbeat_interval(Duration::from_secs(20))       // Optional: Default 20s
    .heartbeat_timeout(Duration::from_secs(60))        // Optional: Default 60s
    .metadata(r#"{"version":"1.0.0"}"#)                // Optional: Custom metadata
    .metadata_store(metadata_store)                    // Required: Coordination store
    .build()
    .await?
```

### Lease Configuration

```rust
// In lease_manager.rs
const DEFAULT_LEASE_DURATION_MS: i64 = 30_000;        // 30 seconds
const LEASE_RENEWAL_INTERVAL: Duration = Duration::from_secs(10); // 10 seconds
```

**Tuning Guidelines**:
- **Shorter leases** (10s) â†’ Faster failover, more PostgreSQL load
- **Longer leases** (60s) â†’ Slower failover, less PostgreSQL load
- **Renewal interval** should be **1/3 of lease duration** (3 attempts per lease)

---

## Monitoring

### Key Metrics

**Agent Health**:
- `agent.heartbeat_age_ms` - Time since last heartbeat
- `agent.heartbeat_failures` - Failed heartbeat attempts
- `agent.state` - Created/Started/Stopped

**Lease Health**:
- `lease.renewal_count` - Total successful renewals
- `lease.renewal_failures` - Failed renewal attempts
- `lease.active_leases` - Number of held leases
- `lease.epoch` - Current epoch per partition

**Failure Detection**:
- `agents.dead_count` - Agents with stale heartbeats
- `leases.expired_count` - Leases past expiration
- `leases.stolen_count` - Leases taken over by another agent

### Dashboard Queries

**List Live Agents**:
```sql
SELECT
    agent_id,
    address,
    availability_zone,
    (NOW() - last_heartbeat) AS heartbeat_age_ms
FROM agents
WHERE last_heartbeat > (NOW() - 60000)
ORDER BY heartbeat_age_ms ASC;
```

**Lease Distribution**:
```sql
SELECT
    leader_agent_id,
    COUNT(*) AS lease_count
FROM partition_leases
WHERE lease_expires_at > NOW()
GROUP BY leader_agent_id
ORDER BY lease_count DESC;
```

**Stale Leases** (potential issues):
```sql
SELECT
    topic,
    partition_id,
    leader_agent_id,
    (NOW() - lease_expires_at) AS expired_ms
FROM partition_leases
WHERE lease_expires_at < NOW()
ORDER BY expired_ms DESC
LIMIT 10;
```

---

## Deployment

### Kubernetes Example

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streamhouse-agents
spec:
  replicas: 6  # Scale horizontally
  selector:
    matchLabels:
      app: streamhouse-agent
  template:
    metadata:
      labels:
        app: streamhouse-agent
    spec:
      containers:
      - name: agent
        image: streamhouse:latest
        env:
        - name: AGENT_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name  # Use pod name
        - name: AGENT_ADDRESS
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: AVAILABILITY_ZONE
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: AGENT_GROUP
          value: "prod"
        - name: POSTGRES_URL
          valueFrom:
            secretKeyRef:
              name: postgres-creds
              key: url
        livenessProbe:
          httpGet:
            path: /health
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 9090
          initialDelaySeconds: 10
          periodSeconds: 10
```

### Docker Compose Example

```yaml
services:
  agent-1:
    image: streamhouse:latest
    environment:
      AGENT_ID: agent-1
      AGENT_ADDRESS: agent-1:9090
      AVAILABILITY_ZONE: us-east-1a
      AGENT_GROUP: prod
      POSTGRES_URL: postgres://...
    ports:
      - "9091:9090"

  agent-2:
    image: streamhouse:latest
    environment:
      AGENT_ID: agent-2
      AGENT_ADDRESS: agent-2:9090
      AVAILABILITY_ZONE: us-east-1b
      AGENT_GROUP: prod
      POSTGRES_URL: postgres://...
    ports:
      - "9092:9090"

  agent-3:
    image: streamhouse:latest
    environment:
      AGENT_ID: agent-3
      AGENT_ADDRESS: agent-3:9090
      AVAILABILITY_ZONE: us-east-1a
      AGENT_GROUP: prod
      POSTGRES_URL: postgres://...
    ports:
      - "9093:9090"
```

---

## FAQ

### Q: Why PostgreSQL instead of Redis/etcd/ZooKeeper?

**A**: Simplicity. We already use PostgreSQL for metadata, so using it for coordination means:
- One less system to operate
- Strong consistency (ACID)
- Familiar SQL interface
- Good enough performance (< 10ms latency)

If you need sub-second failover or multi-region active-active, consider CockroachDB (Phase 5+).

### Q: What happens if PostgreSQL goes down?

**A**: All agents stop writing (coordination plane down). When PostgreSQL recovers, agents reconnect and resume. S3 data is safe (already written).

**Mitigation**: Use PostgreSQL with replication (primary + replicas).

### Q: What happens if an agent crashes mid-write?

**A**:
- S3 segment upload completes or fails (atomic)
- If segment uploaded but metadata not committed â†’ orphaned segment (cleanup later)
- Lease expires after 30s â†’ another agent takes over
- No data corruption (epoch fencing prevents stale writes)

### Q: Can I run multiple agent groups?

**A**: Yes! Use `agent_group` to isolate environments:
- `agent_group: "prod"` - Production workload
- `agent_group: "staging"` - Staging workload
- Agents only see other agents in their group

### Q: How many agents should I run?

**A**:
- **Start**: 3 agents (minimum for HA)
- **Scale**: 1 agent per 100-200 partitions
- **Maximum**: Limited by PostgreSQL (100+ agents easily supported)

---

## Next Steps

1. **Read Phase 4.1 Details**: [PHASE_4.1_COMPLETE.md](./PHASE_4.1_COMPLETE.md)
2. **Read Phase 4.2 Details**: [PHASE_4.2_COMPLETE.md](./PHASE_4.2_COMPLETE.md)
3. **Review Code**: `crates/streamhouse-agent/src/`
4. **Run Tests**: `cargo test --package streamhouse-agent`
5. **Deploy**: Follow Kubernetes/Docker examples above
6. **Monitor**: Set up dashboards with SQL queries above

---

**Last Updated**: 2026-01-24
**Contributors**: Claude Sonnet 4.5
