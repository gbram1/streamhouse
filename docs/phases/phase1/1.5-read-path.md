# Initiative 1.5: Read Path

**Timeline:** Week 4-5
**Goal:** Implement efficient record consumption from S3 with caching and prefetching

---

## Overview

The **Read Path** is how consumers retrieve records from the storage layer. It must efficiently locate segments in S3, download them, cache them locally, and serve records starting from any offset.

The challenge: S3 has high latency (50-200ms per GET), so we need aggressive caching and prefetching to achieve low read latency.

---

## The Complete Read Flow

```
Consumer                                                       S3
   │                                                           │
   │  1. consume("orders", partition=0, offset=50000)         │
   ▼                                                           │
┌──────────────┐                                               │
│ Storage      │  2. Find segment containing offset           │
│ Manager      │     (query metadata store)                   │
└──────┬───────┘                                               │
       │          Segment: s3://.../00000000000000000000.seg   │
       │          Contains offsets 0-99,999                    │
       ▼                                                        │
┌──────────────┐                                               │
│ Segment      │  3. Check local cache                        │
│ Cache        │     Cache key: topic/partition/base_offset   │
└──────┬───────┘                                               │
       │                                                        │
   Cache MISS                                                   │
       │                                                        │
       │  4. Download from S3 ◀─────────────────────────────── │
       ▼                                                        │
┌──────────────┐                                               │
│ Download &   │  5. Save to local disk cache                 │
│ Cache        │     /tmp/cache/topic-partition-offset.seg    │
└──────┬───────┘                                               │
       │                                                        │
       │  6. Open SegmentReader                                │
       ▼                                                        │
┌──────────────┐                                               │
│ Segment      │  7. Use index to find offset 50000           │
│ Reader       │     Read from byte position                  │
└──────┬───────┘                                               │
       │                                                        │
       │  8. Decompress block, extract records                │
       ▼                                                        │
┌──────────────┐                                               │
│ Return       │  9. Stream records back to consumer          │
│ Records      │                                               │
└──────┬───────┘                                               │
       │                                                        │
       │  Background: Prefetch next segment                    │
       │  (for sequential reads)                               │
       ▼                                                        │
   Consumer ◀── [Record, Record, Record, ...]                  │
```

---

## Components

### 1. Segment Cache

Manages local disk cache with LRU eviction.

```rust
// crates/streamhouse-storage/src/cache.rs

use bytes::Bytes;
use lru::LruCache;
use std::num::NonZeroUsize;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::sync::Mutex;

pub struct SegmentCache {
    /// Cache directory on local disk
    cache_dir: PathBuf,

    /// Maximum cache size in bytes
    max_size_bytes: u64,

    /// Current cache size
    current_size: Arc<Mutex<u64>>,

    /// LRU tracker (key -> size)
    lru: Arc<Mutex<LruCache<String, u64>>>,
}

impl SegmentCache {
    pub fn new<P: AsRef<Path>>(cache_dir: P, max_size_bytes: u64) -> Result<Self> {
        let cache_dir = cache_dir.as_ref().to_path_buf();

        // Create cache directory
        std::fs::create_dir_all(&cache_dir)?;

        let capacity = NonZeroUsize::new(10000).unwrap(); // Track up to 10K segments
        let lru = Arc::new(Mutex::new(LruCache::new(capacity)));

        Ok(Self {
            cache_dir,
            max_size_bytes,
            current_size: Arc::new(Mutex::new(0)),
            lru,
        })
    }

    /// Get segment from cache, or None if not cached
    pub async fn get(&self, cache_key: &str) -> Result<Option<Bytes>> {
        let path = self.cache_path(cache_key);

        if !path.exists() {
            return Ok(None);
        }

        // Read from disk
        let data = tokio::fs::read(&path).await?;

        // Update LRU (move to front)
        let mut lru = self.lru.lock().await;
        lru.get(cache_key);

        tracing::debug!(
            cache_key = %cache_key,
            size = data.len(),
            "Cache hit"
        );

        Ok(Some(Bytes::from(data)))
    }

    /// Put segment in cache
    pub async fn put(&self, cache_key: &str, data: Bytes) -> Result<()> {
        let size = data.len() as u64;

        // Make room if needed
        self.evict_if_needed(size).await?;

        // Write to disk
        let path = self.cache_path(cache_key);
        tokio::fs::write(&path, &data).await?;

        // Update tracking
        {
            let mut current_size = self.current_size.lock().await;
            *current_size += size;
        }

        {
            let mut lru = self.lru.lock().await;
            lru.put(cache_key.to_string(), size);
        }

        tracing::debug!(
            cache_key = %cache_key,
            size = data.len(),
            "Cached segment"
        );

        Ok(())
    }

    /// Evict LRU entries until we have enough space
    async fn evict_if_needed(&self, needed: u64) -> Result<()> {
        let mut current_size = self.current_size.lock().await;
        let mut lru = self.lru.lock().await;

        while *current_size + needed > self.max_size_bytes {
            if let Some((cache_key, size)) = lru.pop_lru() {
                // Delete from disk
                let path = self.cache_path(&cache_key);
                if let Err(e) = tokio::fs::remove_file(&path).await {
                    tracing::warn!(
                        cache_key = %cache_key,
                        error = %e,
                        "Failed to delete cached segment"
                    );
                }

                *current_size = current_size.saturating_sub(size);

                tracing::debug!(
                    cache_key = %cache_key,
                    size,
                    "Evicted from cache"
                );
            } else {
                // Cache is empty but we still need space
                // This means the needed size exceeds max_size_bytes
                tracing::warn!(
                    needed,
                    max_size = self.max_size_bytes,
                    "Cannot cache: segment larger than max cache size"
                );
                break;
            }
        }

        Ok(())
    }

    fn cache_path(&self, cache_key: &str) -> PathBuf {
        self.cache_dir.join(format!("{}.seg", cache_key))
    }

    /// Get cache statistics
    pub async fn stats(&self) -> CacheStats {
        let current_size = *self.current_size.lock().await;
        let entry_count = self.lru.lock().await.len();

        CacheStats {
            current_size,
            max_size: self.max_size_bytes,
            entry_count,
            hit_rate: 0.0, // TODO: track hits/misses
        }
    }
}

#[derive(Debug, Clone)]
pub struct CacheStats {
    pub current_size: u64,
    pub max_size: u64,
    pub entry_count: usize,
    pub hit_rate: f64,
}
```

### 2. Partition Reader

Reads from a single partition with caching.

```rust
// crates/streamhouse-storage/src/reader.rs

use crate::cache::SegmentCache;
use crate::segment::SegmentReader;
use bytes::Bytes;
use std::sync::Arc;
use streamhouse_metadata::{MetadataStore, SegmentInfo};
use object_store::ObjectStore;

pub struct PartitionReader {
    topic: String,
    partition_id: u32,
    metadata: Arc<dyn MetadataStore>,
    object_store: Arc<dyn ObjectStore>,
    cache: Arc<SegmentCache>,
}

impl PartitionReader {
    pub fn new(
        topic: String,
        partition_id: u32,
        metadata: Arc<dyn MetadataStore>,
        object_store: Arc<dyn ObjectStore>,
        cache: Arc<SegmentCache>,
    ) -> Self {
        Self {
            topic,
            partition_id,
            metadata,
            object_store,
            cache,
        }
    }

    /// Read records starting from offset
    pub async fn read(
        &self,
        start_offset: u64,
        max_records: usize,
    ) -> Result<ReadResult> {
        // Find segment containing start_offset
        let segment_info = self
            .metadata
            .find_segment_for_offset(&self.topic, self.partition_id, start_offset)
            .await?
            .ok_or_else(|| Error::OffsetNotFound(start_offset))?;

        // Get segment (from cache or S3)
        let segment_data = self.get_segment(&segment_info).await?;

        // Open segment reader
        let reader = SegmentReader::open(segment_data)?;

        // Read records
        let records = reader.read_from(start_offset, max_records)?;

        // Prefetch next segment if we're reading sequentially
        if records.len() == max_records {
            self.prefetch_next_segment(&segment_info).await;
        }

        Ok(ReadResult {
            records,
            high_watermark: segment_info.end_offset + 1,
        })
    }

    /// Get segment data (cache-aware)
    async fn get_segment(&self, info: &SegmentInfo) -> Result<Bytes> {
        let cache_key = self.cache_key(info);

        // Try cache first
        if let Some(data) = self.cache.get(&cache_key).await? {
            tracing::debug!(
                topic = %self.topic,
                partition = self.partition_id,
                base_offset = info.base_offset,
                "Segment cache hit"
            );
            return Ok(data);
        }

        // Cache miss - download from S3
        tracing::debug!(
            topic = %self.topic,
            partition = self.partition_id,
            base_offset = info.base_offset,
            s3_key = %info.s3_key,
            "Segment cache miss, downloading from S3"
        );

        let path = object_store::path::Path::from(&info.s3_key);
        let result = self.object_store.get(&path).await?;
        let data = result.bytes().await?;

        // Cache for future reads
        self.cache.put(&cache_key, data.clone()).await?;

        Ok(data)
    }

    /// Prefetch next segment in background
    fn prefetch_next_segment(&self, current: &SegmentInfo) {
        let next_offset = current.end_offset + 1;
        let topic = self.topic.clone();
        let partition_id = self.partition_id;
        let metadata = self.metadata.clone();
        let object_store = self.object_store.clone();
        let cache = self.cache.clone();

        tokio::spawn(async move {
            // Find next segment
            if let Ok(Some(next_segment)) = metadata
                .find_segment_for_offset(&topic, partition_id, next_offset)
                .await
            {
                let cache_key = format!("{}-{}-{}", topic, partition_id, next_segment.base_offset);

                // Check if already cached
                if cache.get(&cache_key).await.ok().flatten().is_some() {
                    return; // Already cached
                }

                // Download and cache
                tracing::debug!(
                    topic = %topic,
                    partition = partition_id,
                    base_offset = next_segment.base_offset,
                    "Prefetching next segment"
                );

                let path = object_store::path::Path::from(&next_segment.s3_key);
                if let Ok(result) = object_store.get(&path).await {
                    if let Ok(data) = result.bytes().await {
                        let _ = cache.put(&cache_key, data).await;
                    }
                }
            }
        });
    }

    fn cache_key(&self, info: &SegmentInfo) -> String {
        format!("{}-{}-{}", self.topic, self.partition_id, info.base_offset)
    }
}

#[derive(Debug, Clone)]
pub struct ReadResult {
    pub records: Vec<Record>,
    pub high_watermark: u64,
}

#[derive(Debug, Clone)]
pub struct Record {
    pub offset: u64,
    pub timestamp: u64,
    pub key: Option<Bytes>,
    pub value: Bytes,
}
```

### 3. Consumer

High-level consumer API.

```rust
// crates/streamhouse-storage/src/consumer.rs

use crate::reader::PartitionReader;
use bytes::Bytes;

pub struct Consumer {
    group_id: Option<String>,
    topic: String,
    partition_id: u32,
    reader: Arc<PartitionReader>,
    metadata: Arc<dyn MetadataStore>,
    current_offset: u64,
}

impl Consumer {
    pub async fn new(
        topic: String,
        partition_id: u32,
        group_id: Option<String>,
        reader: Arc<PartitionReader>,
        metadata: Arc<dyn MetadataStore>,
    ) -> Result<Self> {
        // Determine starting offset
        let current_offset = if let Some(ref group) = group_id {
            // Resume from committed offset
            metadata
                .get_committed_offset(group, &topic, partition_id)
                .await?
                .unwrap_or(0)
        } else {
            // Start from beginning
            0
        };

        Ok(Self {
            group_id,
            topic,
            partition_id,
            reader,
            metadata,
            current_offset,
        })
    }

    /// Poll for next batch of records
    pub async fn poll(&mut self, max_records: usize) -> Result<Vec<Record>> {
        let result = self
            .reader
            .read(self.current_offset, max_records)
            .await?;

        if !result.records.is_empty() {
            let last_offset = result.records.last().unwrap().offset;
            self.current_offset = last_offset + 1;
        }

        Ok(result.records)
    }

    /// Commit current position (for consumer groups)
    pub async fn commit(&self) -> Result<()> {
        if let Some(ref group) = self.group_id {
            self.metadata
                .commit_offset(
                    group,
                    &self.topic,
                    self.partition_id,
                    self.current_offset,
                    None,
                )
                .await?;

            tracing::debug!(
                group = %group,
                topic = %self.topic,
                partition = self.partition_id,
                offset = self.current_offset,
                "Committed offset"
            );
        }

        Ok(())
    }

    /// Seek to specific offset
    pub fn seek(&mut self, offset: u64) {
        self.current_offset = offset;
    }

    /// Get current position
    pub fn position(&self) -> u64 {
        self.current_offset
    }
}
```

---

## Usage Example

```rust
use streamhouse_storage::{PartitionReader, Consumer, SegmentCache};
use streamhouse_metadata::SqliteMetadataStore;
use object_store::aws::AmazonS3Builder;

#[tokio::main]
async fn main() -> Result<()> {
    // Setup
    let metadata = Arc::new(SqliteMetadataStore::new("metadata.db").await?);

    let object_store = Arc::new(
        AmazonS3Builder::new()
            .with_bucket_name("streamhouse")
            .with_region("us-east-1")
            .with_endpoint("http://localhost:9000")
            .with_access_key_id("minioadmin")
            .with_secret_access_key("minioadmin")
            .build()?,
    );

    let cache = Arc::new(SegmentCache::new(
        "/tmp/streamhouse-cache",
        1024 * 1024 * 1024, // 1GB cache
    )?);

    // Create reader
    let reader = Arc::new(PartitionReader::new(
        "orders".to_string(),
        0,
        metadata.clone(),
        object_store,
        cache,
    ));

    // Create consumer
    let mut consumer = Consumer::new(
        "orders".to_string(),
        0,
        Some("analytics-group".to_string()),
        reader,
        metadata,
    )
    .await?;

    // Consume records
    loop {
        let records = consumer.poll(100).await?;

        if records.is_empty() {
            // No more data, wait a bit
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
            continue;
        }

        for record in records {
            let value_str = String::from_utf8_lossy(&record.value);
            println!("Offset {}: {}", record.offset, value_str);
        }

        // Commit progress
        consumer.commit().await?;
    }
}
```

---

## Configuration

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReadConfig {
    /// Cache directory
    #[serde(default = "default_cache_dir")]
    pub cache_dir: PathBuf,

    /// Maximum cache size in bytes (default: 1GB)
    #[serde(default = "default_cache_size")]
    pub cache_max_size: u64,

    /// Enable prefetching (default: true)
    #[serde(default = "default_true")]
    pub prefetch_enabled: bool,

    /// Fetch size (records per poll)
    #[serde(default = "default_fetch_size")]
    pub fetch_size: usize,
}

fn default_cache_dir() -> PathBuf {
    PathBuf::from("/tmp/streamhouse-cache")
}

fn default_cache_size() -> u64 {
    1024 * 1024 * 1024 // 1GB
}

fn default_true() -> bool {
    true
}

fn default_fetch_size() -> usize {
    1000
}
```

---

## Performance Optimizations

### 1. Parallel Segment Downloads

When consuming from multiple partitions, download in parallel:

```rust
pub async fn read_multiple_partitions(
    partitions: &[PartitionReader],
    offset: u64,
    max_records: usize,
) -> Result<Vec<ReadResult>> {
    let futures: Vec<_> = partitions
        .iter()
        .map(|reader| reader.read(offset, max_records))
        .collect();

    let results = futures::future::try_join_all(futures).await?;
    Ok(results)
}
```

### 2. Range Requests

For large segments, use HTTP range requests to fetch only needed blocks:

```rust
// Instead of downloading entire 64MB segment,
// fetch only the block containing the offset
let range = format!("bytes={}-{}", block_start, block_end);
let result = object_store.get_range(&path, range).await?;
```

### 3. Compression-Aware Caching

Cache decompressed blocks separately to avoid repeated decompression:

```rust
// Cache both compressed segment and decompressed blocks
pub struct BlockCache {
    decompressed_blocks: LruCache<BlockKey, RecordBatch>,
}
```

---

## Testing

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_read_from_cache() {
        let cache = SegmentCache::new("/tmp/test-cache", 100_000_000).unwrap();

        let data = Bytes::from("test data");
        cache.put("test-key", data.clone()).await.unwrap();

        let cached = cache.get("test-key").await.unwrap().unwrap();
        assert_eq!(cached, data);
    }

    #[tokio::test]
    async fn test_cache_eviction() {
        let cache = SegmentCache::new("/tmp/test-cache", 100).unwrap(); // Tiny cache

        // Fill cache beyond capacity
        cache.put("key1", Bytes::from(vec![0u8; 50])).await.unwrap();
        cache.put("key2", Bytes::from(vec![1u8; 50])).await.unwrap();
        cache.put("key3", Bytes::from(vec![2u8; 50])).await.unwrap(); // Should evict key1

        // key1 should be evicted
        assert!(cache.get("key1").await.unwrap().is_none());
        assert!(cache.get("key2").await.unwrap().is_some());
        assert!(cache.get("key3").await.unwrap().is_some());
    }

    #[tokio::test]
    async fn test_consumer_poll() {
        // Setup test environment
        // ... create metadata, object store, etc ...

        let mut consumer = Consumer::new(
            "test".to_string(),
            0,
            None,
            reader,
            metadata,
        )
        .await
        .unwrap();

        let records = consumer.poll(10).await.unwrap();
        assert_eq!(records.len(), 10);
        assert_eq!(records[0].offset, 0);
        assert_eq!(records[9].offset, 9);
    }
}
```

---

## Performance Targets

| Metric | Target | Notes |
|--------|--------|-------|
| Read latency (cached) | < 10ms p99 | Segment in cache |
| Read latency (uncached) | < 200ms p99 | First S3 download |
| Sequential read throughput | 100K records/sec | With prefetching |
| Cache hit rate | > 80% | For sequential reads |

---

## Deliverables

At the end of Initiative 1.5, you will have:

- [ ] **SegmentCache** with LRU eviction
- [ ] **PartitionReader** with S3 integration
- [ ] **Consumer** API for easy consumption
- [ ] **Prefetching** for sequential reads
- [ ] **Tests** verifying cache and read logic
- [ ] **Benchmarks** measuring read performance

---

## Next Steps

After completing the Read Path (Initiative 1.5), you'll move to:

**Initiative 1.6: API Server** - Build gRPC services to expose produce and consume functionality to clients.

---

## Dependencies

```toml
[dependencies]
streamhouse-core = { path = "../streamhouse-core" }
streamhouse-metadata = { path = "../streamhouse-metadata" }
bytes = "1.5"
tokio = { version = "1.35", features = ["full"] }
object_store = { version = "0.9", features = ["aws"] }
lru = "0.12"
tracing = "0.1"
thiserror = "1.0"
serde = { version = "1.0", features = ["derive"] }
```

---

## Time Estimate

**Total: 1-1.5 weeks** (assuming 25-35 hours of work)

- SegmentCache implementation: 6-8 hours
- PartitionReader: 5-7 hours
- Consumer API: 3-4 hours
- Prefetching logic: 3-4 hours
- Testing and benchmarking: 6-8 hours
- Documentation: 2-3 hours
